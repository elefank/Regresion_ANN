{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión utilizando una red neuronal (ANN)\n",
    "\n",
    "El dataset (Training_set), contiene un millón de observaciones de 25 variables, asumimos que son (independientes), y una variable de respuesta \"y\".\n",
    "Nuestro objetivo será poder predecir la variable y a partir de x1,x2...,x25.\n",
    "\n",
    "Para ello utilizaremos Keras para generar un modelo simple pero capáz de realizar está tarea.\n",
    "\n",
    "Las variables 'x' son numéricas x1,x2...,x25 lo mismo que la variable 'y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las dependencias que vamos a utilizar\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Tomé esta función del repositorio de Jeff Heaton (Washington Univerity) \n",
    "# https://github.com/jeffheaton\n",
    "# toma un dataframe de pandas y convierte sus elememtos en enteros o flotantes de 32 bits\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos los datos de entenamiento\n",
    "df=pd.read_csv(\"TrainingSet.csv\")\n",
    "#print(df.head())\n",
    "\n",
    "# Eliminamos las variables que no tienen nombre (en este caso index (o rownames))\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\QuirozH\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Aquí utilizamos la función to_xy, donde dividimos el data frame en dos, X (predictores) & y (variable de respuesta)\n",
    "# luego convertimos la codificación a tipo flotante de 32 bits\n",
    "\n",
    "X,y = to_xy(df,\"y\")\n",
    "\n",
    "# el warning puede ser ignorado por ahora está usando una función que va a desaparecer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un conhjunto de entrenamiento y uno de prueba (30%) de los datos seran del set de prueba\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 25)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos las dimensiones del set de datos creado\n",
    "X_train.shape[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 16s - loss: 2.9470\n",
      "Epoch 2/10\n",
      " - 16s - loss: 0.1248\n",
      "Epoch 3/10\n",
      " - 16s - loss: 0.1044\n",
      "Epoch 4/10\n",
      " - 16s - loss: 0.0879\n",
      "Epoch 5/10\n",
      " - 16s - loss: 0.0781\n",
      "Epoch 6/10\n",
      " - 16s - loss: 0.0710\n",
      "Epoch 7/10\n",
      " - 16s - loss: 0.0628\n",
      "Epoch 8/10\n",
      " - 16s - loss: 0.0594\n",
      "Epoch 9/10\n",
      " - 16s - loss: 0.0559\n",
      "Epoch 10/10\n",
      " - 16s - loss: 0.0533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0ae49de10>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aqui definimos el modelo de red neuronal (ANN)\n",
    "model = Sequential()\n",
    "\n",
    "# Agregamos capas densas (fully connected), especificando el número de nodos, y en la primera capa el numero de inputs\n",
    "# usamos la funcion de activación relu\n",
    "model.add(Dense(25, input_dim=X_train.shape[1], activation='relu')) # Hidden 1\n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "\n",
    "# Dado que el objetivo es la regresión, la última capa poseé solo un nodo que será la respuesta de predicción\n",
    "model.add(Dense(1)) # Output\n",
    "\n",
    "# Aquí definimos la función de error que será minimizada y el algoritmo utilizado para ello, 'adam' es una variante de SGD\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Aquí comienza en entrenamiento:\n",
    "# Para cada epoca estamos utilizando todos los datos de entrenamiento, esto podría ser modificado para entrenar por batchs (secciones)\n",
    "model.fit(X_train,y_train,verbose=2,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (300000, 1)\n",
      "[[21.838556]\n",
      " [14.0237  ]\n",
      " [21.29497 ]\n",
      " ...\n",
      " [ 9.533099]\n",
      " [15.696542]\n",
      " [16.45551 ]]\n"
     ]
    }
   ],
   "source": [
    "# Tomámos los inputs del set de prueba y predecimos su valor de Y \n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"Shape: {}\".format(pred.shape))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.180473193526268\n"
     ]
    }
   ],
   "source": [
    "# Tomamos los valores predichos y los comparamos con los valores reales, calculamos una metrica de desempeño de la red\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(f\"Final score (RMSE): {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Y-Actual: [21.86156], Y-predicted : [21.838556]\n",
      "2. Y-Actual: [13.829164], Y-predicted : [14.0237]\n",
      "3. Y-Actual: [21.597174], Y-predicted : [21.29497]\n",
      "4. Y-Actual: [13.7927475], Y-predicted : [13.896361]\n",
      "5. Y-Actual: [11.677943], Y-predicted : [11.7009]\n",
      "6. Y-Actual: [15.559005], Y-predicted : [15.524943]\n",
      "7. Y-Actual: [9.624718], Y-predicted : [9.48198]\n",
      "8. Y-Actual: [16.590979], Y-predicted : [16.602133]\n",
      "9. Y-Actual: [7.7023554], Y-predicted : [7.846073]\n",
      "10. Y-Actual: [10.5246935], Y-predicted : [10.487618]\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los primeros 10 resultados entre el valor de Y actual y el predicho por la red\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. Y-Actual: {y_test[i]}, Y-predicted : {pred[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x0        x1        x2        x3        x4        x5        x6  \\\n",
      "0  0.644144  0.380748  0.663048  0.163651  0.962608  0.346662  0.991751   \n",
      "1  0.286435  0.555613  0.376420  0.026624  0.494149  0.834715  0.366987   \n",
      "2  0.784654  0.264857  0.339367  0.814370  0.807455  0.493562  0.845312   \n",
      "\n",
      "         x7        x8        x9    ...          x15       x16       x17  \\\n",
      "0  0.235058  0.585694  0.406690    ...     0.089703  0.195771  0.994194   \n",
      "1  0.515382  0.472379  0.386152    ...     0.244832  0.697950  0.212081   \n",
      "2  0.365190  0.047831  0.264146    ...     0.684491  0.324034  0.576812   \n",
      "\n",
      "        x18       x19       x20       x21       x22       x23       x24  \n",
      "0  0.235180  0.238986  0.629100  0.734953  0.688344  0.031131  0.902514  \n",
      "1  0.267293  0.373894  0.573089  0.917358  0.818976  0.163181  0.024155  \n",
      "2  0.632650  0.596462  0.137827  0.618001  0.493464  0.143612  0.030822  \n",
      "\n",
      "[3 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# cargamos los datos no vistos por el modelo\n",
    "df_test = pd.read_csv(\"TestSet.csv\")\n",
    "\n",
    "# eliminamos las variables que no tienen nombre\n",
    "X_final=df_test.loc[:, ~df_test.columns.str.contains('^Unnamed')]\n",
    "\n",
    "print(X_final.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 1)\n"
     ]
    }
   ],
   "source": [
    "# ajustamos con el nuevo dataset \n",
    "y_final = model.predict(X_final)\n",
    "\n",
    "# convertimos a dataframe\n",
    "y_final = pd.DataFrame(data=y_final, columns=['y'])\n",
    "\n",
    "print(y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la nueva columna en el data frame\n",
    "final = final.assign(y=pd.Series(y_final['y']).values)\n",
    "#print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportamos el data frame como CSV\n",
    "final.to_csv(\"PredictionsANN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
